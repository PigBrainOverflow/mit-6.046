{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floyd-Warshall\n",
    "\n",
    "IDEA: $dp(u, v, k)$ represents the shortest path from $u$ to $v$ whose intermediate vertices $\\in \\{1, 2, \\cdots, k\\}$.  \n",
    "$$\n",
    "\\begin{align}\n",
    "dp(u, v, k) &= \\min\\{dp(u, v, k-1), dp(u, k, k-1) + dp(k, v, k-1)\\} \\\\\n",
    "dp(u, v, 0) &= w_{uv}\n",
    "\\end{align}\n",
    "$$\n",
    "$u$ is in a negative weight cycle if $dp(u, u, n) < 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Spanning Tree\n",
    "\n",
    "1. The idea behind Greedy Algorithm: If you can solve a subproblem optimally, then you can get the total optimal solution from the subproblem.\n",
    "\n",
    "2. Lemma 1 (idea behind Kruskal's Algorithm): If $e_{u,v} \\in T^*$, where $T^*$ is an MST of $G$, and $T'$ is an MST of $G/\\{e_{u,v}\\}$, then $T'\\cup \\{e_{u,v}\\}$ is an MST of $G$. Note: When we subtract an edge from a graph, we actually contract (fuse) the both vertices from the edge. $w(T')\\le w(T^*) - w(e_{u,v})$ and $w(T) = w(T'\\cup \\{e_{u,v}\\}) \\le w(T^*)$. $T$ is also an MST of $G$.\n",
    "\n",
    "3. Lemma 2 (idea behind Prim's Algorithm): For any cut of graph $G$, its minimum crossing edge must be in an MST of $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem 6-1\n",
    "\n",
    "Suppose $G_{i,j}$ is the weight of edge from $i$ to $j$ ($G_{i,j} = +\\infty$ if there's no edge from $i$ to $j$), $D_{i,j} = \\delta(i,j)$, $\\Pi_{i,j}$ is the predecessor of vertex $j$ in the shortest path from $i$ to $j$.\n",
    "\n",
    "1.\n",
    "    - $r = G_{i,j}$: No update needed.\n",
    "    - $r < G_{i,j}$: We update with $D'_{k,l} = \\min\\{D_{k,i} + r + D_{j,l}, D_{k,l}\\}$ and also its $\\Pi'$. The time complexity is $O(n^2)$.\n",
    "    - $r > G_{i,j}$: For each source vertex $s$, we can apply DFS on vertex $j$: For each of its out vertices $k$, if $\\Pi_{s,k} = j$, namely $j$ is $k$'s predecessor, we should recalculate $D_{s,k}$ and $\\Pi_{s,k}$. If we make a successful update, we should recursively apply DFS on $k$. The time complexity is also $O\\left(|V|(|V|+|E|)\\right) = O(|V|^2 + |V||E|) = O(n^3)$.\n",
    "\n",
    "2. A complete graph linked with a source vertex $0$: $\\forall i, j > 0, G_{i,j} = 1$ and $G_{0,1} = 1$. When we modify $G_{0,1}$ to $0$, considering source vertex $0$, we have roughly $|E| = |V|^2$ edges to traverse in order to update $\\forall i > 1, D_{0, i}$ from $2$ to $1$.\n",
    "\n",
    "3.\n",
    "    $dp(u, v, k, l)$ represents the shortest path from $u$ to $v$ with at most $l$ edges whose intermediate vertices $\\in \\{1, 2, \\cdots, k\\}$.\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    dp(u,v,k,l) &= \\min_{m = 0}^{l}\\{dp(u,v,k-1,l), dp(u,k,k-1,m)+dp(k,v,k-1,l-m)\\} \\\\\n",
    "    dp(u,u,0,0) &= 0 \\\\\n",
    "    dp(u,v,0,1) &= G_{u,v}\n",
    "    \\end{align}\n",
    "    $$\n",
    "    The time complexity is $O(n^3h^2)$.\n",
    "\n",
    "4.\n",
    "    We define $C = A \\odot B$ as $c_{i,j} = min_k\\{a_{i,k} + b_{k,j}\\}$. Therefore, $D^{(m)}$ means the distance matrix with at most $m$ hops. The reason why it can be treated as matrix multiplication is that it also follows associative laws. The time complexity is $O(n^3\\log h)$\n",
    "\n",
    "5.\n",
    "    We need $2^k$-hop distance matrices $\\{D^{(1)}, D^{(2)}, D^{(4)}, \\cdots, D^{(\\lceil \\frac{h}{2} \\rceil)}\\}$ and their corresponding predecessor matrices $\\{\\Pi^{(1)}, \\Pi^{(2)}, \\Pi^{(4)}, \\cdots, \\Pi^{(\\lceil \\frac{h}{2} \\rceil)}\\}$, whose entries are $\\Pi_{i,j}^{(2l)} = \\argmin_{k}\\{D^{(l)}_{i,k} + D^{(l)}_{k,j}\\}$.\n",
    "    - $r = G_{i,j}$: No update needed.\n",
    "    - $r < G_{i,j}$: We look through $\\{\\Pi^{(1)}, \\Pi^{(2)}, \\Pi^{(4)}, \\cdots, \\Pi^{(\\lceil \\frac{h}{2} \\rceil)}\\}$ until we find an entry is $j$, then update the following $\\Pi$. The time complexity is $O(n^3\\log h)$.\n",
    "    - $r > G_{i,j}$: Recalculate $D$ and $\\Pi$. The time complexity is $O(n^3\\log h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem 6-2\n",
    "\n",
    "1. Suppose $T^*$ is the unique MST of $G$. Proof by contradiction: There's another MST $T$ distinct from $T^*$, which means $\\exist e_{u,v} \\in T,e_{u,v} \\notin T^*$. Divide $T$ at $e_{u,v}$ into $T_u$ and $T_v$, $T_u \\subset G_u, T_v\\subset G_v$, where $G_u$ and $G_v$ is a cut of $G$. Therefore, by lemma 2, we know that a minimum edge $e^*\\in T^*$ must connect $G_u$ and $G_v$ but since the weights are distinct, $e^* < e_{u,v}$. If we substitute $e_{u,v}$ with $e^*$ in $T$, it will be smaller and thus our assumption $T^*$ is not minimum.\n",
    "\n",
    "2. It's correct. For each phase, assume the components formed by $A$ are $\\{C_1, C_2, \\cdots, C_n\\}$ and the edges they choose are respectively $E = \\{e_1, e_2, \\cdots, e_n\\}$. We create $E'$ by sorting the edges in ascending order and removing the duplicated. There must be no ring in $E'$, otherwise the ring will cause a contradiction: $e'_{i_1} > e'_{i_2} > \\cdots > e'_{i_k} > e'_{i_1}$. Finally, adding the edges in $E'$ one by one is equal to applying $|E'|$ phases of Kruskal's Algorithm.\n",
    "\n",
    "3. It's correct, supported by Lemma 2.\n",
    "\n",
    "4. It's correct. Proof by contradiction: Suppose $T$ is an MST generated by removing not the heaviest edge in at least one cycle. We can easily recover that cycle and remove the heaviest instead, creating $T'$, where $w(T') < w(T)$. Then $T$ is not an MST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
