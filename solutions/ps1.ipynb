{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tractability\n",
    "\n",
    "1. P: can be solved in polynomial time.\n",
    "2. NP: can be verified in polynomial time.\n",
    "3. NP-complete: the hardest problems in NP, can be solved in exponential time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paradigm to Prove Greedy Algorithms\n",
    "\n",
    "1. Claim: Suppose given the input $I$, the greedy algorithm produces the optimal solution $k^*$.\n",
    "2. Prove by Induction: Suppose our claim holds for $k^*$, then the algorithm also produces the optimal solution $k^* + 1$. We try to construct a solution by our algorithm based on $k^*$ that is no worse than the real optimal solution.\n",
    "\n",
    "IDEA!: Induction on either problem size or solution size. At every step of the algorithm, the greedy choice we make doesn’t rule out an optimal solution. By the end of the algorithm, we’ve got some solution, so it must be optimal! In other words, at every step of the algorithm, there is always an optimal solution that extends the set of choices we made so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem 1-1\n",
    "\n",
    "1.  \n",
    "```\n",
    "[9] -- [10] -- [9]\n",
    "```\n",
    "2. Dynamic Programming on Tree: We start at an arbitrary vertex and create a tree by DFS.  \n",
    "$dp(u, True)$ means the maximum profit of the subtree $u$ if $u$ is chosen, and $dp(u, False)$ means that if $u$ is not chosen. We have\n",
    "\\begin{align}\n",
    "dp(u, True) & = \\sum_{v\\in children(u)}dp(v, False) + p_u \\\\\n",
    "dp(u, False) & = \\sum_{v\\in children(u)}\\max\\left(dp(v, True), dp(v, False)\\right) \\\\\n",
    "\\end{align}\n",
    "The total time complexity is $O(n)$.\n",
    "3. Same as 2 but with $p_u = 1$.\n",
    "4. Backtracking: We traverse the whole graph by DFS. For each vertex, we try choosing it or not, and after we finish the whole graph, calculate its sum, otherwise, we backtrack.  \n",
    "The total time complexity is $O(2^n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem 1-2\n",
    "\n",
    "1. Because the distance of each other must be less than $\\frac{\\sqrt{2}}{2}$.\n",
    "2. Divide-and-Conquer:  \n",
    "First, we divide $L_x$ into two halves: $L_{x,left} = L_x[0 : m]$ and $L_{x,right} = L_x[m :]$, where $m = \\lceil \\frac{n}{2} \\rceil, n = len(L_x)$. Divide $L_y$ into two halves: $L_{y,left} = filter(L_y, x < x_m)$ and $L_{y,right} = filter(L_y, x \\ge x_m)$. The time complexity is $O(n)$.  \n",
    "Second, we apply our algorithm respectively on $L_{x,left}, L_{y,left}$ and $L_{x,right}, L_{y,right}$. If the result of either of them is $True$, return $True$.  \n",
    "How to merge? Double-pointer and Sliding-window! For each $(x_i, y_i)$ in $L_{y,left}$, we maintain all coordinates in range $[(x_m, y_i - 1), (x_m + 1, y_i + 1)]$ in $L_{y,right}$ and calculate their distances to $(x_i, y_i)$. There must be less than $6$ points in this $1 \\times 2$ rectangle. The time complexity is $O(n)$.  \n",
    "The total time complexity $T(n) = 2T(\\frac{n}{2}) + O(n) = O(nlogn)$.\n",
    "3. Divide-and-Conquer:  \n",
    "Similar to 2 but in each subproblem with $n$ points, we should maintain a list of coordinate pairs $(p_i, p_j)$, where the distance between $p_i$ and $p_j$ is less than $1$. Obivously, there must be less than $3$ points in any equilateral triangle with side length $1$ so the $1 \\times 2$ rectangle has less than $18$ points inside. (It can be tighter but I believe $6$ triangles are enough to cover the rectangle.)  \n",
    "Therefore, the total time complexity is still $O(nlogn)$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
